# -*- coding: utf-8 -*-
"""data prepocessing_climate changes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TFH2YHpR-Nyc05juPRygKp4GJ-G8ycXQ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import opendatasets as od

"""**download and load the datasets**"""

od.download(
    "https://www.kaggle.com/datasets/greegtitan/indonesia-climate?select=climate_data.csv")

df = pd.read_csv('/content/indonesia-climate/climate_data.csv')
df.head()

"""Desc

1.   Tn:	min temperature (°C)
2.   Tx:	max temperature (°C)
3. Tavg:	avg temperature (°C)

1.   RH_avg:	avg humidity (%)
2.   RR:	rainfall (mm)

6.   ss:	duration of sunshine (hour)
7. ff_x:	max wind speed (m/s)
8. ddd_x:	wind direction at maximum speed (°)
9. ff_avg:	avg wind speed (m/s)
10. ddd_car:	most wind direction (°)
11. station_id:	station id which record the data. Detail of the station can be found in station_detail.csv





"""

df_station = pd.read_csv('/content/indonesia-climate/station_detail.csv')
df_station.head()

df_province=pd.read_csv('/content/indonesia-climate/province_detail.csv')
df_province.head()

"""**merged datasets**"""

df_merged_1 = df_station.merge(df_province, on = ["province_id"], how = 'left')
df_merged_1.head()

df_merged = df.merge(df_merged_1, on = ["station_id"], how = 'left')
df_merged.head()

df_merged.nunique()

"""**choose only several features that will be used in data dashboard**"""

df_new = df_merged[['date', 'Tn', 'Tx', 'Tavg', 'RH_avg', 'RR', 'ss', 'station_id', 'station_name', 'latitude', 'longitude', 'region_name', 'region_id', 'province_id', 'province_name']]
df_new.head()

"""**drop outliers**"""

df_new.Tn.nlargest(10), df_new.Tn.nsmallest(15)

df_new.drop(df['Tn'].nlargest(2).index, axis=0, inplace=True)

df_new.Tx.nlargest(10), df_new.Tn.nsmallest(10)

df_new.drop(df['Tx'].nlargest(4).index, axis=0, inplace=True)

df_new.Tavg.nlargest(10), df_new.Tn.nsmallest(10)

df_new.drop(df['Tavg'].nlargest(2).index, axis=0, inplace=True)

df_new.RH_avg.nlargest(10), df_new.Tn.nsmallest(10)

df_new.drop(df['RH_avg'].nlargest(3).index, axis=0, inplace=True)

df_new.RR.nlargest(10), df_new.Tn.nsmallest(15)

df_new.drop(df['RR'].nlargest(5).index, axis=0, inplace=True)

df_new.ss.nlargest(10), df_new.Tn.nsmallest(15)

df_new.drop(df['ss'].nlargest(3).index, axis=0, inplace=True)

"""**check null values**"""

df_new.isna().sum()

"""fill null values -> here i am using backward fill since the data is sorted based on the station_id group, it is likely that the values in the next row still belong to data with the same station_id"""

df_new_ver = df_new.bfill()
df_new_ver.isna().sum()

"""formatting date"""

df_new_ver.date = pd.to_datetime(df_new_ver.date, format = '%d-%m-%Y')
df_new_ver.head()

df_new_ver.describe().T

df_new_ver.to_csv('climate-change-clean.csv', index=False)